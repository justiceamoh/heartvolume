{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep Neural Network Regressor - Rework for TBME\n",
    "\n",
    "My first stab at this task will be to implement an **DNN Regressor** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Basic Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold01_log.csv\tFold04_log.csv\tFold07_log.csv\tFold10_log.csv\ttrain.csv\r\n",
      "Fold02_log.csv\tFold05_log.csv\tFold08_log.csv\tREADME.docx\r\n",
      "Fold03_log.csv\tFold06_log.csv\tFold09_log.csv\ttest.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data7/train.csv',header=None)\n",
    "# print df.info()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data = df.iloc[:,:-1].values.reshape((-1,30,224))\n",
    "# y_data = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load function\n",
    "def load_data(filename,prints=False,spatial=False):\n",
    "    data   = pd.read_csv(filename,header=None)\n",
    "    if spatial:\n",
    "        x_data = data.iloc[:,:-1].values.reshape((-1,30,224,1))\n",
    "    else:\n",
    "        x_data = data.iloc[:,:-1].values\n",
    "    y_data = data.iloc[:,-1].values\n",
    "    if prints:\n",
    "        print 'X shape:', x_data.shape\n",
    "        print 'Y shape:', y_data.shape\n",
    "    return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataid   = 7\n",
    "filename = 'data{}/train.csv'.format(dataid)\n",
    "x_train,y_train=load_data(filename,spatial=True)\n",
    "scaler   = MinMaxScaler(feature_range=(0,1)).fit(y_train.reshape(-1,1))\n",
    "y_train  = scaler.transform(y_train.reshape(-1,1)).squeeze()\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_train,y_train,test_size=0.25,random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Imports\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Lambda, AveragePooling2D\n",
    "from keras.layers import Flatten, Reshape,Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Params\n",
    "num_batch = 28\n",
    "num_epoch = 30\n",
    "patience  = 10\n",
    "\n",
    "# Parameters\n",
    "# ndim = x_train.shape[1]\n",
    "npat,ndim,_ = x_train.shape[1:]\n",
    "L1   = 127\n",
    "L2   = 169\n",
    "L3   = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DNN\n",
    "def build_model(cnn=False):\n",
    "    if not cnn:\n",
    "        x = Input(shape=(ndim,),name='Input')\n",
    "        h = Dense(L1,activation='relu',name='L1')(x)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Dense(L2,activation='relu',kernel_regularizer=regularizers.l2(0.01),name='L2')(h)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Dense(L3,activation='relu',kernel_regularizer=regularizers.l2(0.01),name='L3')(h)\n",
    "        h = BatchNormalization()(h)\n",
    "        y = Dense(1,activation='linear',name='Output')(h)\n",
    "        \n",
    "    else:\n",
    "        x = Input(shape=(npat,ndim,1),name='Input')\n",
    "        h = Conv2D(28,kernel_size=(3,5),strides=(2,3),padding='same',name='L1')(x)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Dropout(0.2)(h)\n",
    "        h = Conv2D(16,kernel_size=(3,3),strides=(2,3),padding='same',name='L2')(h)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Dropout(0.2)(h)\n",
    "        h = Conv2D(15,kernel_size=(3,3),strides=(1,3),padding='same',name='L3')(h)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Dropout(0.2)(h)\n",
    "        h = AveragePooling2D((2,2),strides=(2,2))(h)\n",
    "        h = Flatten()(h)\n",
    "        h = Dense(7,activation='relu',kernel_regularizer=regularizers.l2(0.01),name='L4')(h)\n",
    "        y = Dense(1,activation='linear',name='Output')(h)\n",
    "\n",
    "    model = Model(x,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = build_model(cnn=True)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "modelname  = 'hypermodel.h5'\n",
    "e_stopper  = EarlyStopping(monitor='val_loss', min_delta=0, patience=10)\n",
    "checkpoint = ModelCheckpoint(modelname,monitor='val_loss',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "log = model.fit(x_train, y_train,\n",
    "              batch_size=num_batch,\n",
    "              epochs=num_epoch,\n",
    "              shuffle=True,\n",
    "              callbacks=[e_stopper,checkpoint],\n",
    "              validation_data=(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model{}.h5'.format(dataid))\n",
    "model = load_model(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training Curves\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(log.epoch,log.history['loss'])\n",
    "plt.plot(log.epoch,log.history['val_loss'],'g')\n",
    "plt.title('Training Curves')\n",
    "# plt.ylim([0,0.05])\n",
    "plt.xlabel('Epochs')\n",
    "plt.xlabel('MSE Loss')\n",
    "plt.legend(['Train','Valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate Predictions for Test Set\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "fname = 'data{}/test.csv'.format(dataid)\n",
    "x_test,y_test=load_data(fname,spatial=True)\n",
    "y_test = scaler.transform(y_test.reshape(-1,1)).squeeze()\n",
    "y_predict = model.predict(x_test)\n",
    "loss = model.evaluate(x_test,y_test,verbose=0)\n",
    "\n",
    "\n",
    "# y_tst = scaler.inverse_transform(y_test.squeeze())\n",
    "# y_prd = scaler.inverse_transform(y_predict.squeeze())\n",
    "plt.subplot(111)\n",
    "plt.plot(y_test,'o-',alpha=0.5)\n",
    "plt.plot(y_predict,'go-')\n",
    "header = '{0}, mse={1:.02f}'.format(fname[9:-4],loss)\n",
    "plt.title(header)\n",
    "\n",
    "# oname = 'data{}/ypred.csv'.format(dataid)\n",
    "# tname = 'data{}/ytest.csv'.format(dataid)\n",
    "# np.savetxt(oname,y_predict,delimiter=',')\n",
    "# np.savetxt(tname,y_test,delimiter=',')\n",
    "\n",
    "plt.legend(['Original','Predicted'],loc=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
